{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ea000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for initializing the SIR sub-population of each node\n",
    "def decomposition(i,k):\n",
    "    while k > 0:\n",
    "        if k ==1:\n",
    "            n = i\n",
    "        else:\n",
    "            n = random.randint(0, i)\n",
    "        yield n\n",
    "        i -= n\n",
    "        k -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializtion_mobility_network\n",
    "def initializtion_mobility_network(number_of_node, average_in_degree, average_out_degree):\n",
    "    ### node generation\n",
    "    num_node = number_of_node\n",
    "    G_saved = nx.DiGraph()\n",
    "\n",
    "    ##generate the node \n",
    "    G_saved.add_nodes_from(nx.path_graph(num_node))\n",
    "    for i in range(len(G_saved.nodes())):\n",
    "        # S, I, R\n",
    "        num_pop = round(np.random.normal(10000,2500,1)[0])\n",
    "        G_saved._node[i].update({'cont_popu': num_pop})\n",
    "        G_saved._node[i].update({'status': [num_pop,0,0]})\n",
    "        G_saved._node[i].update({'record':[G_saved._node[i]['status']]})\n",
    "        G_saved._node[i].update({'stayed': num_pop})\n",
    "        G_saved._node[i].update({'tem_popu':num_pop})\n",
    "        G_saved._node[i].update({'tem_status':[0,0,0]})\n",
    "        G_saved._node[i].update({'tem_popu_rate':[st/num_pop for st in G_saved._node[i]['status']]})\n",
    "\n",
    "    initial_infected_list = random.sample(range(len(G_saved.nodes())), 5)\n",
    "    for i in initial_infected_list:\n",
    "        tem =nx.get_node_attributes(G_saved,'status')[i]\n",
    "        G_saved._node[i].update({'status':[tem[0]-10, tem[1]+10, 0]})\n",
    "        G_saved._node[i].update({'record':[G_saved._node[i]['status']]})\n",
    "\n",
    "\n",
    "    sorted_popu={k: v for k, v in sorted(nx.get_node_attributes(G_saved, 'cont_popu').items(), key=lambda item: item[1],reverse=True)}\n",
    "    \n",
    "    print('initially infected towns list: ', initial_infected_list)\n",
    "    print('information of initially infected towns list:', [nx.get_node_attributes(G_saved,'status')[i] for i in initial_infected_list])\n",
    "\n",
    "    ###### edge generation\n",
    "\n",
    "    # for out edges of the mobility network\n",
    "    G_o = nx.barabasi_albert_graph(num_node,average_out_degree)\n",
    "    # for in edges of the mobility network\n",
    "    G_i = nx.barabasi_albert_graph(num_node,average_in_degree)\n",
    "\n",
    "    sorted_o = [ node for (node, val) in sorted(G_o.degree(), key=lambda pair: pair[1],reverse=True )]\n",
    "    sorted_o_map =  dict(zip(sorted_o ,sorted_popu.keys()))\n",
    "    G_o = nx.relabel_nodes(G_o, sorted_o_map )\n",
    "    sorted_i = [ node for (node, val) in sorted(G_i.degree(), key=lambda pair: pair[1],reverse=True )]\n",
    "    sorted_i_map =  dict(zip(sorted_i ,sorted_popu.keys()))\n",
    "    G_i = nx.relabel_nodes(G_i, sorted_i_map )\n",
    "\n",
    "    ## set the max_weight of each edge based on the population\n",
    "    max_weight_list = [round(list(nx.get_node_attributes(G_saved,'cont_popu').values())[i]/(num_node/3)) for i in range(num_node)]\n",
    "    for edge_added in G_i.edges():\n",
    "        G_saved.add_edge(edge_added[1], edge_added[0], weight=random.sample(range(10,max_weight_list[edge_added[1]]),1)[0])\n",
    "    for edge_added in G_o.edges():\n",
    "        G_saved.add_edge(edge_added[0], edge_added[1], weight=random.sample(range(10,max_weight_list[edge_added[0]]),1)[0])\n",
    "\n",
    "    ### add edges if some node has no in-mobility or out-mobnility to avoid the isolaiton\n",
    "    for i in G_saved.out_degree():\n",
    "        if i[1] == 0:\n",
    "            #print('no out nodes: ',  i[0])\n",
    "            for k in random.sample([m for m in range(num_node) if m != i[0]],5):\n",
    "                #print(k)\n",
    "                G_saved.add_edge(i[0], k,weight=random.sample(range(10,max_weight_list[i[0]]),1)[0]) \n",
    "    for i in G_saved.in_degree():\n",
    "        if i[1] == 0:\n",
    "            #print('no in nodes: ', i[0])\n",
    "            for k in random.sample([m for m in range(num_node) if m != i[0]],5):\n",
    "                #print(k)\n",
    "                G_saved.add_edge(k, i[0],weight=random.sample(range(10,max_weight_list[k]),1)[0])\n",
    "    \n",
    "    return(G_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a36510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_metapopulation_simulation(G_input,duration_input, edg_changed_input, wei_changed_input):\n",
    "    for i in range(len(G_input)):\n",
    "        G_input._node[i].update({'record':[G_input._node[i]['status']]})\n",
    "\n",
    "    edge_martix_record = []\n",
    "    num_node = len(G_input)\n",
    "#     for i in range(num_node):\n",
    "#         G_input._node[i].update({'record':[G_input._node[i]['status']]})\n",
    "    G = G_input.copy()\n",
    "    ## set the max_weight of each edge based on the population\n",
    "    max_weight_list = [round(list(nx.get_node_attributes(G,'cont_popu').values())[i]/(num_node/3)) for i in range(num_node)]\n",
    "    \n",
    "    ## the parameters for the dynamic mobility netwoek\n",
    "    edg_changed_rate = edg_changed_input\n",
    "    wei_changed_rate = wei_changed_input\n",
    "    \n",
    "    ### simualtion \n",
    "    total_edge_change_pro = 1\n",
    "    edge_added_record = [len(G.edges)]\n",
    "    duration = duration_input\n",
    "    for time in range(duration):\n",
    "        if time ==0:\n",
    "            edge_pool =  list(permutations(range(len(G.nodes())), 2))\n",
    "            edge_added = list(G.edges)\n",
    "        ### the rest process\n",
    "        else:\n",
    "            if total_edge_change_pro < 1:\n",
    "                check_have_in_out = -1\n",
    "                while check_have_in_out <0:\n",
    "                    check_have_in_out = 1\n",
    "                    edge_modified = random.sample(edge_added,round(len(edge_added)-\n",
    "                                                                   len(edge_added)* total_edge_change_pro))\n",
    "                    for check_edge in edge_modified:\n",
    "                        if G.in_degree(check_edge[1]) <3 or G.out_degree(check_edge[0])<3:\n",
    "                            check_have_in_out = -1\n",
    "                G.remove_edges_from(edge_modified)\n",
    "                difference_pool = list(set(edge_added).difference(set(edge_modified)))\n",
    "                edge_added = difference_pool\n",
    "            if total_edge_change_pro > 1:\n",
    "                complement_pool = list(set(edge_pool) - (set(edge_added)))\n",
    "                edge_modified = random.sample(complement_pool,-round(len(edge_added)\n",
    "                                                                     -len(edge_added)* total_edge_change_pro))\n",
    "                for sro, tar in edge_modified:\n",
    "                    G.add_edge(sro, tar, weight=random.sample(range(1,max_weight_list[sro]),1)[0])\n",
    "                edge_added += edge_modified\n",
    "            edge_added_record.append(len(edge_added))\n",
    "\n",
    "            ## update the weight of the edge\n",
    "            for i in G.edges():\n",
    "                tem_w = G.edges()[i]['weight']\n",
    "                G.edges()[i]['weight'] = max(10, round(tem_w*homo_weight_change_pro))\n",
    "\n",
    "\n",
    "        ## update the tem information\n",
    "        ## calculate the number of stayed\n",
    "        weight_list =nx.get_edge_attributes(G, 'weight')\n",
    "        for i in range(len(G.nodes())):\n",
    "            G._node[i].update({'stayed': G._node[i]['cont_popu']- G.out_degree(weight = 'weight')[i]})\n",
    "\n",
    "        ## calculate the distribution of stayed people\n",
    "        for i in range(len(G.nodes())):\n",
    "             G._node[i].update({'tem_status': [G._node[i]['stayed']*sir for sir in G._node[i]['tem_popu_rate']]})\n",
    "\n",
    "        ## calculate the new pop        \n",
    "        for edg in  G.edges():\n",
    "            tem_in_node = edg[1]\n",
    "            tem_out_node = edg[0]\n",
    "            ## the distrbution of go out people per link \n",
    "            tem_out_dis = [weight_list[edg]* dis for dis in G._node[edg[0]]['tem_popu_rate']]\n",
    "            pre_dis =  G._node[edg[1]]['tem_status'].copy()\n",
    "            G._node[edg[1]].update({'tem_status':[a + b for a, b in zip(pre_dis, tem_out_dis)]})\n",
    "\n",
    "        for i in range(len(G.nodes())):\n",
    "             G._node[i].update({'tem_popu': sum( G._node[i]['tem_status'])})\n",
    "\n",
    "        ##SIR model\n",
    "        in_ra_s = 0.25\n",
    "        in_ra_m = 3\n",
    "        re_ra = 0.25\n",
    "        for node in range(len(G.nodes())):\n",
    "            stayed_S_to_I = G._node[node]['stayed']* G._node[node]['tem_popu_rate'][0]*G._node[node]['tem_status'][1]/G._node[node]['tem_popu']*in_ra_s\n",
    "            out_S_to_I = 0\n",
    "            for out_edg in G.out_edges([node]):\n",
    "                des = out_edg[1]\n",
    "                tem_out_S_to_I = weight_list[out_edg]* G._node[node]['tem_popu_rate'][0]*G._node[des]['tem_status'][1]/G._node[des]['tem_popu']*in_ra_m\n",
    "                out_S_to_I += tem_out_S_to_I\n",
    "            #print(node,stayed_S_to_I,out_S_to_I)\n",
    "            S_to_I = round(stayed_S_to_I + out_S_to_I)\n",
    "            I_to_R = round(G._node[node]['cont_popu']* G._node[node]['tem_popu_rate'][1]*re_ra)\n",
    "            pre_status = G._node[node]['status'].copy()\n",
    "            G._node[node].update({'status': [pre_status[0]-S_to_I,pre_status[1]+S_to_I-I_to_R,pre_status[2]+I_to_R]})\n",
    "            G._node[node]['record'].append(G._node[node]['status'])\n",
    "\n",
    "        ## record the edges information overtime\n",
    "        tem_edge_matrix = nx.adjacency_matrix(G).A\n",
    "        for node in range(len(G.nodes())):\n",
    "            tem_edge_matrix[node][node] += G._node[node]['stayed']\n",
    "        edge_martix_record.append(tem_edge_matrix)\n",
    "\n",
    "\n",
    "        #G.remove_edges_from(list(G.edges()))\n",
    "        for i in range(len(G.nodes())):\n",
    "            G._node[i].update({'tem_popu_rate':[st/G._node[node]['cont_popu'] for st in G._node[i]['status']]})\n",
    "\n",
    "        whole_R_changed = sum([nx.get_node_attributes(G,'record')[i][time+1][1]-nx.get_node_attributes(G,'record')[i][time][1] for i in range(len(G))])\n",
    "        total_edge_change_pro = round(math.e**(-whole_R_changed/(2000*edg_changed_rate)),2)\n",
    "        homo_weight_change_pro = round(math.e**(-whole_R_changed/(2000*wei_changed_rate)),2)\n",
    "\n",
    "    stayed_record = []\n",
    "    for j in range(duration):\n",
    "        stayed_record.append(sum([edge_martix_record[j][i][i]/G._node[i]['cont_popu'] for i in range(num_node)])/(num_node))\n",
    "\n",
    "    I_record = []\n",
    "    for i in range(duration):\n",
    "        tem_I = 0\n",
    "        for j in range(num_node):\n",
    "            tem_check = nx.get_node_attributes(G,'record')[j]\n",
    "            tem_I += tem_check[i][1]\n",
    "        I_record.append(tem_I)\n",
    "\n",
    "    tem = nx.from_numpy_matrix(np.matrix(edge_martix_record[0]), create_using=nx.DiGraph)\n",
    "    tem.remove_edges_from(nx.selfloop_edges(tem))\n",
    "    nx.set_edge_attributes(tem, 0, \"anti_weight\")\n",
    "    for i in tem.edges:\n",
    "        tem.edges[i]['anti_weight'] = 1/ tem.edges[i]['weight']\n",
    "\n",
    "    # save the data\n",
    "    data_record =  pd.DataFrame(columns = ['town','day', 'population','S', 'I', 'R', \n",
    "                                           'in_flow', 'out_flow', 'intra_flow','in_link', 'out_link',\n",
    "                                          'In_pr', 'Out_pr','Bet_wei','de_cen', 'in_de_cen', 'out_de_cen',\n",
    "                                           'all_I','I_t_1'])\n",
    "    for dd in range(duration):\n",
    "        ## geneate the network and calculate the network centrality\n",
    "        tem = nx.from_numpy_matrix(np.matrix(edge_martix_record[dd]), create_using=nx.DiGraph)\n",
    "        tem.remove_edges_from(nx.selfloop_edges(tem))\n",
    "        nx.set_edge_attributes(tem, 0, \"anti_weight\")\n",
    "        tem_all_I = sum([nx.get_node_attributes(G,'record')[td][dd][1] for td in range(num_node)])\n",
    "        for i in tem.edges:\n",
    "            tem.edges[i]['anti_weight'] = 1/ tem.edges[i]['weight']\n",
    "        tem_in_pr = nx.pagerank(tem,alpha=0.8)\n",
    "        tem_out_eigen = nx.pagerank(tem.reverse(copy=True), weight = 'weight' )\n",
    "        tem_bet_weight_cen = nx.betweenness_centrality(tem, weight  = 'anti_weight')\n",
    "        tem_de_cen  =  nx.degree_centrality(G)\n",
    "        tem_de_in_cen = nx.in_degree_centrality(G)\n",
    "        tem_de_out_cen = nx.out_degree_centrality(G)\n",
    "        for tt in range(num_node):\n",
    "            tem_used = [tt, dd, G._node[tt]['cont_popu']]\n",
    "            tem_used += nx.get_node_attributes(G,'record')[tt][dd]\n",
    "\n",
    "            tem_out_flow =sum(edge_martix_record[dd][tt])-edge_martix_record[dd][tt,tt]\n",
    "            tem_intra_flow =edge_martix_record[dd][tt,tt]\n",
    "            tem_in_flow =edge_martix_record[dd][:, tt].sum()-edge_martix_record[dd][tt,tt]\n",
    "            tem_out_link = np.count_nonzero(edge_martix_record[dd][tt])-1\n",
    "            tem_in_link = np.count_nonzero(edge_martix_record[dd][:, tt])-1\n",
    "            tem_used.append(tem_in_flow)\n",
    "            tem_used.append(tem_out_flow)\n",
    "            tem_used.append(tem_intra_flow)\n",
    "            tem_used.append(tem_in_link)\n",
    "            tem_used.append(tem_out_link)\n",
    "            tem_used.append(tem_in_pr[tt])\n",
    "            tem_used.append(tem_out_eigen[tt])\n",
    "            tem_used.append(tem_bet_weight_cen[tt])\n",
    "            tem_used.append(tem_de_cen[tt])\n",
    "            tem_used.append(tem_de_in_cen[tt])\n",
    "            tem_used.append(tem_de_out_cen[tt])\n",
    "            tem_used.append(tem_all_I)\n",
    "            if dd ==0:\n",
    "                tem_used.append(0)\n",
    "            else:\n",
    "                tem_used.append(nx.get_node_attributes(G,'record')[tt][dd-1][1])\n",
    "\n",
    "            data_record .loc[len(data_record )]=tem_used\n",
    "            \n",
    "        \n",
    "    return(data_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8478caa",
   "metadata": {},
   "source": [
    "# Mobility Network Generation and simulation (with Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d119454",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generat the initial mobility network\n",
    "### input:  number_of_node, average_in_degree, average_out_degree\n",
    "G_saved = initializtion_mobility_network(50, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c98d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the SIR model\n",
    "### input: initial mobility network, duration, change_rate_of_edge, change_rate_of_weight\n",
    "tem = SIR_metapopulation_simulation(G_saved, 10, 25, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b72909",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c0c130",
   "metadata": {},
   "source": [
    "# Four scenarios study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d782b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the paramter setting for four scenarios study\n",
    "scenario_num_list = [[200,500],[100,250], [50,100], [25,50]]\n",
    "scenario_fir_record = [[],[],[]] \n",
    "scenario_sec_record = [[],[],[]] \n",
    "scenario_thi_record = [[],[],[]]\n",
    "scenario_fou_record = [[],[],[]] \n",
    "scenario_whole_record = [scenario_fir_record,scenario_sec_record,scenario_thi_record,scenario_fou_record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for round_num in tqdm(range(5)):\n",
    "    G_tem = initializtion_mobility_network(50, 10, 10)\n",
    "    for sc_num in range(len(scenario_num_list)) :\n",
    "        data_record = SIR_metapopulation_simulation(G_tem, 50, scenario_num_list[sc_num][0], scenario_num_list[sc_num][1])\n",
    "        \n",
    "        data=data_record.copy()\n",
    "        basic = ['all_I', 'in_flow']\n",
    "        basic_in = basic[0]\n",
    "        for tem_ad in range(len(basic)-1):\n",
    "            basic_in += \" + \" \n",
    "            basic_in += basic[tem_ad+1]\n",
    "        basic_mod = ols(formula='I_t_1 ~ {} + C(town)'.format(basic_in), data=data)\n",
    "        basic_res = basic_mod.fit(cov_type='cluster',cov_kwds={'groups': data['town']},use_t=True)\n",
    "        tem_basic_line = basic_res.rsquared_adj\n",
    "        para_name_used = ['In_pr', 'Out_pr','Bet_wei']\n",
    "        for net_pa_in in range(len(para_name_used)) :\n",
    "            data=data_record.copy()\n",
    "            basic =['all_I', 'in_flow'] + [para_name_used[net_pa_in]]\n",
    "            basic_in = basic[0]\n",
    "            for tem_ad in range(len(basic)-1):\n",
    "                basic_in += \" + \" \n",
    "                basic_in += basic[tem_ad+1]   \n",
    "            developed_mod = ols(formula='I_t_1 ~ {} + C(town)'.format(basic_in), data=data)\n",
    "            developed_res = developed_mod.fit(cov_type='cluster',cov_kwds={'groups': data['town']},use_t=True)\n",
    "            developed_res_added  =  developed_res.rsquared_adj\n",
    "            scenario_whole_record[sc_num][net_pa_in].append(developed_res_added/tem_basic_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa70bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a603331a",
   "metadata": {},
   "source": [
    "# Show the result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c84502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_test = scenario_whole_record.copy()\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        tem_test[i][j] = [k-1 for k in tem_test[i][j]]\n",
    "\n",
    "data_showed =  pd.DataFrame(columns = ['Edge_changed_rate','Weight_changed_rate','In_pr', 'Out_pr','Bet_wei'], index = ['slow', 'medium', 'fast', 'sharp'])\n",
    "data_showed['Edge_changed_rate'] = [200,100,50,25]\n",
    "data_showed['Weight_changed_rate'] = [500,250,100,50]\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        tem_mean = round((np.mean(tem_test[i][j]))*100,2)\n",
    "        tem_std = round(np.std(tem_test[i][j])*100,2)\n",
    "        data_showed.iloc[i,j+2] = '{}% \\u00B1 {}%'.format(tem_mean,tem_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835140b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0e4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264138d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
